---
title: "Build a face recognition backend"
date: 2020-03-03T10:15:55-07:00
chapter: true
draft: false
weight: 323
tags:
  - intermediate
---



To recognize faces, we will use [Amazon Rekognition collections](https://docs.aws.amazon.com/rekognition/latest/dg/collections.html). A collection is a container for persisting faces detected by the [IndexFaces](https://docs.aws.amazon.com/rekognition/latest/dg/API_IndexFaces.html) API action. Amazon Rekognition doesn’t store copies of the analyzed images. Instead, it stores face feature vectors as the mathematic representation of a face within the collection.

You can use the facial information in a collection to search for known faces in images, stored videos, and streaming videos.

To create a collection you will first need to configure the AWS CLI:


+ [Install the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/installing.html)
+ [Configure the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html)

1. Create an empty Amazon Rekognition collection using this CLI command:

```bash
aws rekognition create-collection --collection-id "Faces" --region us-east-1 
```
2. Now, we are going to create an Amazon DynamoDB table for storing unique face feature vectors generated by Amazon Rekognition and the number of coffees each person had.

DynamoDB works well for this use case. As a fully managed service, you don’t need to worry about the elasticity and scalability of the database because there is no limit to the amount of data that can be stored in a DynamoDB table. As the size of the data set grows, DynamoDB automatically spreads the data over sufficient machine resources to meet storage requirements. If you weren’t using DynamoDB, the incremental count added to the table would require you to scale accordingly. As for pricing, with DynamoDB you only pay for the resources you provision. For this use case, though, it is quite possible to remain within the AWS Free Tier pricing model or have the project running at a low DynamoDB [price point](https://aws.amazon.com/dynamodb/pricing/).

To create the table in DynamoDB, in the AWS [Management Console](https://console.aws.amazon.com/console/home), navigate to the DynamoDB console and create a table. Use __Faces__ as the table name and __faceID__ as the primary key, and leave the other settings as defaults.

We’ll also create a table named __logs__ for storing the logs of your Lambda function. For this table use unixtime as the primary key.

3.  Create an AWS Lambda function that calls Amazon Rekognition. First, go to the IAM console and create a role for AWS Lambda function. Apply the following managed policies to this role:

* AmazonRekognitionFullAccess
* AmazonDynamoDBFullAccess
* AmazonS3FullAccess
* AWSLambdaExecute

You should follow [AWS IAM best practices](http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html) for production implementations.

4. Finally, navigate to the Lambda console. Create a Lambda function with Python 3.6 as a runtime. Set the name of the S3 bucket that you configured before as your Lambda trigger. Configure the Event type, Prefix, and Suffix as shown in the following screenshot. This ensures that your Lambda function is triggered only when new .jpg objects that start with a key matching the images/ pattern are created within the bucket.

![](/images/040_track_coffee_consumption/043_deploy_face_detection/coffee-counter-9.gif)

Replace the template Lambda code with the code you downloaded from GitHub. Modify the Lambda timeout to 1 minute.

Copy the code from the [GitHub repository](https://github.com/aws-samples/aws-deeplens-coffee-leaderboard/blob/master/face_function.py) and paste in in the code box. Let’s inspect the Lambda code to understand what it’s doing:

```python
  response = rekognition.detect_labels(Image=image, MaxLabels=123, MinConfidence=50)    
    for object in response["Labels"]:
        if object["Name"] == "Coffee Cup" or object["Name"] == "Cup":
            coffee_cup_detected = True
            break        
            ::
        message = detect_faces(image, bucket, key)   
```

This part of code uses AWS Rekognition to detect the labels in the image. It checks if “Cup” or “Coffee Cup” is found in a response. If it finds any of these labels, it calls a face detection function, which searches the face collection to find if there is a matching face:

```python
faces = rekognition.search_faces_by_image(CollectionId=face_collection, Image=image,
                                              FaceMatchThreshold=face_match_threshold, MaxFaces=1)
```
If no matching faces are found in the collection, the face is indexed and added to the collection:

```python
faces = rekognition.index_faces(Image=image, CollectionId=face_collection)
```

To test the function, you can upload an image to your S3 bucket and check your DynamoDB table to see the result.
